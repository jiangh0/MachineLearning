{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os, gc\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./clean_data/xgb_fraud_with_magic_train.csv')\n",
    "X_test = pd.read_csv('./clean_data/xgb_fraud_with_magic_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择训练数据column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card5',\n",
    "       'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain',\n",
    "       'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9',\n",
    "       'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5',\n",
    "       'D10', 'D11', 'D15', 'M1', 'M2', 'M3', 'M4', 'M6', 'M7', 'M8',\n",
    "       'M9', 'V1', 'V3', 'V4', 'V6', 'V8', 'V11', 'V13', 'V14', 'V17',\n",
    "       'V20', 'V23', 'V26', 'V27', 'V30', 'V36', 'V37', 'V40', 'V41',\n",
    "       'V44', 'V47', 'V48', 'V54', 'V56', 'V59', 'V62', 'V65', 'V67',\n",
    "       'V68', 'V70', 'V76', 'V78', 'V80', 'V82', 'V86', 'V88', 'V89',\n",
    "       'V91', 'V107', 'V108', 'V111', 'V115', 'V117', 'V120', 'V121',\n",
    "       'V123', 'V124', 'V127', 'V129', 'V130', 'V136', 'V138', 'V139',\n",
    "       'V142', 'V147', 'V156', 'V160', 'V162', 'V165', 'V166', 'V169',\n",
    "       'V171', 'V173', 'V175', 'V176', 'V178', 'V180', 'V182', 'V185',\n",
    "       'V187', 'V188', 'V198', 'V203', 'V205', 'V207', 'V209', 'V210',\n",
    "       'V215', 'V218', 'V220', 'V221', 'V223', 'V224', 'V226', 'V228',\n",
    "       'V229', 'V234', 'V235', 'V238', 'V240', 'V250', 'V252', 'V253',\n",
    "       'V257', 'V258', 'V260', 'V261', 'V264', 'V266', 'V267', 'V271',\n",
    "       'V274', 'V277', 'V281', 'V283', 'V284', 'V285', 'V286', 'V289',\n",
    "       'V291', 'V294', 'V296', 'V297', 'V301', 'V303', 'V305', 'V307',\n",
    "       'V309', 'V310', 'V314', 'V320', 'id_01', 'id_02', 'id_03', 'id_04',\n",
    "       'id_05', 'id_06', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13',\n",
    "       'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_28',\n",
    "       'id_29', 'id_31', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType',\n",
    "       'DeviceInfo', 'cents', 'addr1_FE', 'card1_FE', 'card2_FE',\n",
    "       'card3_FE', 'P_emaildomain_FE', 'card1_addr1',\n",
    "       'card1_addr1_P_emaildomain', 'card1_addr1_FE',\n",
    "       'card1_addr1_P_emaildomain_FE', 'TransactionAmt_card1_mean',\n",
    "       'TransactionAmt_card1_std', 'TransactionAmt_card1_addr1_mean',\n",
    "       'TransactionAmt_card1_addr1_std',\n",
    "       'TransactionAmt_card1_addr1_P_emaildomain_mean',\n",
    "       'TransactionAmt_card1_addr1_P_emaildomain_std', 'D9_card1_mean',\n",
    "       'D9_card1_std', 'D9_card1_addr1_mean', 'D9_card1_addr1_std',\n",
    "       'D9_card1_addr1_P_emaildomain_mean',\n",
    "       'D9_card1_addr1_P_emaildomain_std', 'D11_card1_mean',\n",
    "       'D11_card1_std', 'D11_card1_addr1_mean', 'D11_card1_addr1_std',\n",
    "       'D11_card1_addr1_P_emaildomain_mean',\n",
    "       'D11_card1_addr1_P_emaildomain_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n",
    "X_train['DT_M'] = X_train['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "X_train['DT_M'] = (X_train['DT_M'].dt.year-2017)*12 + X_train['DT_M'].dt.month \n",
    "\n",
    "y_train = X_train['isFraud'].copy()\n",
    "\n",
    "\n",
    "X_test['DT_M'] = X_test['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "X_test['DT_M'] = (X_test['DT_M'].dt.year-2017)*12 + X_test['DT_M'].dt.month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1099.33 MB\n",
      "Memory usage after optimization is: 277.09 MB\n",
      "Decreased by 74.8%\n",
      "Memory usage of dataframe is 939.38 MB\n",
      "Memory usage after optimization is: 240.16 MB\n",
      "Decreased by 74.4%\n",
      "CPU times: user 38.2 s, sys: 34.8 s, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "y_train = y_train.astype(np.int8)\n",
    "\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionID', 'TransactionAmt', 'ProductCD', 'card1', 'card2',\n",
       "       'card3', 'card4', 'card5', 'card6', 'addr1',\n",
       "       ...\n",
       "       'D9_card1_addr1_mean', 'D9_card1_addr1_std',\n",
       "       'D9_card1_addr1_P_emaildomain_mean', 'D9_card1_addr1_P_emaildomain_std',\n",
       "       'D11_card1_mean', 'D11_card1_std', 'D11_card1_addr1_mean',\n",
       "       'D11_card1_addr1_std', 'D11_card1_addr1_P_emaildomain_mean',\n",
       "       'D11_card1_addr1_P_emaildomain_std'],\n",
       "      dtype='object', length=241)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = X_train.columns\n",
    "train_cols = train_cols.drop(['isFraud', 'TransactionDT', 'DT_M'])\n",
    "train_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN 75% PREDICT 25%\n",
    "idxT = X_train.index[:3*len(X_train)//4]\n",
    "idxV = X_train.index[3*len(X_train)//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# default_params = {'n_estimators':5000, 'cmax_depth':12, 'learning_rate':0.02,\n",
    "#                   'subsample':0.8, 'colsample_bytree':0.4, 'missing':-1}\n",
    "\n",
    "# params_select = {'n_estimators':[3000, 5000, 7000], \n",
    "#                'max_depth':[8, 12, 16], \n",
    "#                'learning_rate':[0.01, 0.03, 0.05, 0.08], \n",
    "#                'subsample':[0.4, 0.6, 0.8, 1.0, 1.2], \n",
    "#                'colsample_bytree':[0.2, 0.4, 0.6, 0.8, 1.0]}\n",
    "\n",
    "# clf = xgb.XGBClassifier(\n",
    "#             missing=-1,\n",
    "#             eval_metric='auc',\n",
    "#             # USE CPU\n",
    "#             nthread=24,\n",
    "#             tree_method='hist'\n",
    "#             # USE GPU\n",
    "# #                 tree_method='gpu_hist' \n",
    "#         )\n",
    "        \n",
    "# gsearch = GridSearchCV(clf, param_grid=params_select, scoring='roc_auc', cv=[(idxT, idxV)])\n",
    "# gsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best score: %0.3f\" % gsearch.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = gsearch.best_estimator_.get_params()\n",
    "# for param_name in sorted(params_select.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# result = pd.DataFrame.from_dict(gsearch.cv_results_)\n",
    "# result.to_csv('./output/xgb_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import xgboost as xgb\n",
    "# params_select = {'n_estimators':[1000, 3000, 5000, 7000, 9000], \n",
    "#                'max_depth':[4, 8, 16, 20], \n",
    "#                'learning_rate':[0.01, 0.03, 0.05, 0.08, 0.11], \n",
    "#                'subsample':[0.4, 0.6, 1.0, 1.2], \n",
    "#                'colsample_bytree':[0.2, 0.6, 0.8, 1.0]}\n",
    "# result = pd.DataFrame(columns=['n_estimators', 'n_estimators_params', 'max_depth', 'max_depth_params',\n",
    "#                                'learning_rate', 'learning_rate_params', 'subsample', 'subsample_params',\n",
    "#                                'colsample_bytree', 'colsample_bytree_params' ])\n",
    "\n",
    "# for (name, value_list) in params_select.items():\n",
    "#     for i, value in enumerate(value_list):\n",
    "#         params = {name: value}\n",
    "        \n",
    "#         print(\"params：%s, value:%d\"%(name, value))\n",
    "#         clf = xgb.XGBClassifier(\n",
    "#             missing=-1,\n",
    "#             eval_metric='auc',\n",
    "#             # USE CPU\n",
    "#             nthread=24,\n",
    "#             tree_method='hist'\n",
    "#             # USE GPU\n",
    "# #                 tree_method='gpu_hist' \n",
    "#         )\n",
    "#         clf.set_params(**params)\n",
    "#         clf.fit(X_train[train_cols].iloc[idxT], y_train.iloc[idxT], \n",
    "#                 eval_set=[(X_train[train_cols].iloc[idxV],y_train.iloc[idxV])],\n",
    "#                 verbose=100, early_stopping_rounds=200)\n",
    "\n",
    "#         result.loc[i, name] = roc_auc_score(y_train.iloc[idxV], clf.predict_proba(X_train[train_cols].iloc[idxV])[:,1])\n",
    "#         result.loc[i, name+'_params'] = value\n",
    "#     result.to_csv('./output/xgb_'+name+'_params.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rows of train = 453219 rows of holdout = 137321\n",
      "[0]\tvalidation_0-auc:0.75801\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[100]\tvalidation_0-auc:0.87186\n",
      "[200]\tvalidation_0-auc:0.89072\n",
      "[300]\tvalidation_0-auc:0.89992\n",
      "[400]\tvalidation_0-auc:0.90268\n",
      "[500]\tvalidation_0-auc:0.90363\n",
      "[600]\tvalidation_0-auc:0.90312\n",
      "[700]\tvalidation_0-auc:0.90371\n",
      "[800]\tvalidation_0-auc:0.90325\n",
      "Stopping. Best iteration:\n",
      "[663]\tvalidation_0-auc:0.90399\n",
      "\n",
      " rows of train = 488908 rows of holdout = 101632\n",
      "[0]\tvalidation_0-auc:0.82505\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[100]\tvalidation_0-auc:0.90321\n",
      "[200]\tvalidation_0-auc:0.92941\n",
      "[300]\tvalidation_0-auc:0.94144\n",
      "[400]\tvalidation_0-auc:0.94542\n",
      "[500]\tvalidation_0-auc:0.94640\n",
      "[600]\tvalidation_0-auc:0.94680\n",
      "[700]\tvalidation_0-auc:0.94662\n",
      "[800]\tvalidation_0-auc:0.94682\n",
      "[900]\tvalidation_0-auc:0.94658\n",
      "Stopping. Best iteration:\n",
      "[772]\tvalidation_0-auc:0.94684\n",
      "\n",
      " rows of train = 497955 rows of holdout = 92585\n",
      "[0]\tvalidation_0-auc:0.82083\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[100]\tvalidation_0-auc:0.90168\n",
      "[200]\tvalidation_0-auc:0.92592\n",
      "[300]\tvalidation_0-auc:0.93882\n",
      "[400]\tvalidation_0-auc:0.94460\n",
      "[500]\tvalidation_0-auc:0.94618\n",
      "[600]\tvalidation_0-auc:0.94697\n",
      "[700]\tvalidation_0-auc:0.94708\n",
      "[800]\tvalidation_0-auc:0.94712\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "params = {'n_estimators':5000, 'max_depth':12, 'learning_rate':0.02,\n",
    "                  'subsample':0.8, 'colsample_bytree':0.4}\n",
    "\n",
    "skf = GroupKFold(n_splits=6)\n",
    "\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_train_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = train_cols\n",
    "\n",
    "for i, (idxT, idxV) in enumerate( skf.split(X_train, y_train, groups=X_train['DT_M']) ):\n",
    "    print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n",
    "    clf = xgb.XGBClassifier(missing=-1, eval_metric='auc',\n",
    "        # USE CPU\n",
    "        nthread=24, tree_method='hist'\n",
    "        # USE GPU\n",
    "#         tree_method='gpu_hist' \n",
    "    )\n",
    "    clf.set_params(**params)\n",
    "    clf.fit(X_train[train_cols].iloc[idxT], y_train.iloc[idxT], \n",
    "            eval_set=[(X_train[train_cols].iloc[idxV],y_train.iloc[idxV])],\n",
    "            verbose=100, early_stopping_rounds=200)\n",
    "\n",
    "    feature_importances[f'fold_{i + 1}'] = clf.feature_importances_\n",
    "    y_train_preds[idxV] += clf.predict_proba(X_train[train_cols].iloc[idxV])[:,1]\n",
    "    y_preds += clf.predict_proba(X_test[train_cols])[:,1]/skf.n_splits\n",
    "    del clf\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CV auc 0.9417165849751634\n"
     ]
    }
   ],
   "source": [
    "print ('XGBoost CV auc', roc_auc_score(y_train, y_train_preds))\n",
    "\n",
    "# 存储预测结果\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submission.isFraud = y_preds\n",
    "sample_submission.to_csv('./output/xgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(16, 16))\n",
    "feature_importances['average'] = feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(skf.n_splits)]].mean(axis=1)\n",
    "sns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\n",
    "plt.title('50 most important feature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
